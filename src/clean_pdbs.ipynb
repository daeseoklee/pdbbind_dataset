{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cf72fe-35ab-4054-a9f1-60dd5aafba7c",
   "metadata": {},
   "source": [
    "# Goal\n",
    "* generate polymer-concatenated clean version of PDBBind *_protein.pdb \n",
    "* generate an entrycode-FASTA index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1afb306c-1b0d-44b7-b305-c8e77d99a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3947b740-fbd4-4e1c-86c1-5f8dedd6804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_residue = {\n",
    "'ALA':'A', 'VAL':'V', 'PHE':'F', 'PRO':'P', 'MET':'M',\n",
    "'ILE':'I', 'LEU':'L', 'ASP':'D', 'GLU':'E', 'LYS':'K',\n",
    "'ARG':'R', 'SER':'S', 'THR':'T', 'TYR':'Y', 'HIS':'H',\n",
    "'CYS':'C', 'ASN':'N', 'GLN':'Q', 'TRP':'W', 'GLY':'G',\n",
    "'MSE':'M', 'ASX':'B', 'UNK' : 'X', 'SEC':'U','PYL':'O'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234be8c3-735b-4bca-ae97-a80df57b4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_set_dir = Path('../pdbbind/v2016/general-set-except-refined')\n",
    "refined_set_dir = Path('../pdbbind/v2016/refined-set')\n",
    "set_dirs = [general_set_dir, refined_set_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3a3b1-9017-4ef2-bc18-5501aff94f77",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating clean pdbs\n",
    "\n",
    "### Assumptions \n",
    "Note that this depends on the following assumptions(loosely checked) on the PDBBind dataset,\n",
    "* all non-polymer HETATM records are pushed at the end of the sequence section, omitting chainID information\n",
    "* At the end of every polymer chain, there is a TER record\n",
    "* Only one model\n",
    "* No 'disorder'  \n",
    "\n",
    "### Procedure\n",
    "\n",
    "* Loop through ATOM/HETATM entries, while pushing the pair of (chainID, exact line) to a **queue**.\n",
    "* When the queue has been nonempty, **assert** the newest chainID is identical to the last one\n",
    "* Each time encountering TER, pop and append to a \"list of output lines\" \n",
    "* At EOL, **assert** that every remaining item in the queue has chainID ' '\n",
    "* write the list of output lines to a file, while\n",
    "  * skipping if the atom is 'H' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1460b43-7074-498f-a7ee-37f1f584d96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "l = [(0, 'a'), (0, 'b'), (0, 'c')]\n",
    "print(all(a == 0 for a, _ in l))\n",
    "print(all([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "552566fe-fd8d-4428-a013-de1433086c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_clean_version(pdb_file, code):\n",
    "    output_lines = []\n",
    "    with open(pdb_file, 'r') as f:\n",
    "        queue = []\n",
    "        for line in f:\n",
    "            if line.startswith('ATOM') or line.startswith('HETATM'):\n",
    "                chainID = line[21]\n",
    "                if queue != []:\n",
    "                    last_chainID, _ = queue[-1]\n",
    "                    if last_chainID != chainID:\n",
    "                        raise Exception('chainID changed without TER:', str(pdb_file), line)\n",
    "                queue.append((chainID, line))\n",
    "            elif line.startswith('TER'):\n",
    "                output_lines += [line for _, line in queue]\n",
    "                queue = [] \n",
    "            else:\n",
    "                continue\n",
    "        if not all(chainID == ' ' for chainID, _ in queue):\n",
    "            raise Exception('EOL without TER for an non-empty chainID:', str(pdb_file))\n",
    "    clean_pdb_file = pdb_file.parent / f'{code}_clean.pdb'\n",
    "    with open(clean_pdb_file, 'w') as f:\n",
    "        for line in output_lines:\n",
    "            if line[76:78].strip() != 'H':\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82aa2922-caf5-4073-8573-f6ab8d3ab131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_over_data_dirs():\n",
    "    for set_dir in set_dirs:\n",
    "        print(set_dir)\n",
    "        for data_dir in tqdm(list(set_dir.glob('*'))):\n",
    "            if data_dir.name in ['readme', 'index']:\n",
    "                continue\n",
    "            yield data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb3c82ad-dccf-4d78-b508-0c52754c5fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/general-set-except-refined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9228/9228 [00:45<00:00, 202.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/refined-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4059/4059 [00:19<00:00, 209.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_dir in loop_over_data_dirs():\n",
    "    protein_file = data_dir / f'{data_dir.name}_protein.pdb'    \n",
    "    write_clean_version(protein_file, data_dir.name)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df6654-1de9-4900-8902-067c480f20fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checking whether the generated clean pdb files look find \n",
    "* Manually check the HETATM resnames \n",
    "* Ensuring that seqres records and residues coincide, with 70 exceptions \n",
    "* Every residue contains 'CA' (Actually, 571 exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e5098-27a0-4085-adbe-1736aaa06d2c",
   "metadata": {},
   "source": [
    "### Resname checking procedure\n",
    "* collect all hetcodes \n",
    "* print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5d2f284-f8f7-4bcf-9502-88732d611f7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/general-set-except-refined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9228/9228 [00:11<00:00, 810.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/refined-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4059/4059 [00:04<00:00, 837.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "CSO\n",
      "MLY\n",
      "SEP\n",
      "TPO\n",
      "CSD\n",
      "ACE\n",
      "LLP\n",
      "KCX\n",
      "PCA\n",
      "PTR\n"
     ]
    }
   ],
   "source": [
    "hetcodes = set([])\n",
    "for data_dir in loop_over_data_dirs():\n",
    "    clean_pdb_file = data_dir / f'{data_dir.name}_clean.pdb'\n",
    "    with open(clean_pdb_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('HETATM'):\n",
    "                hetcode = line[17:20]\n",
    "                hetcodes.add(hetcode) \n",
    "for hetcode in hetcodes:\n",
    "    print(hetcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f2dd4-36ae-4bf5-bba7-cea0dec1a3c9",
   "metadata": {},
   "source": [
    "### Checking CA \n",
    "* Loop over lines:\n",
    "  * When either \n",
    "    * you encounter a new residue or\n",
    "    * EOL \n",
    "  * assert you have a CA atom in the previous residue \n",
    "* Record related statistics while doing that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbb8a95a-bbfd-4372-b757-4b8e4e3f6d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/general-set-except-refined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9228/9228 [00:36<00:00, 251.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/refined-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4059/4059 [00:15<00:00, 268.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of cases at least one CA is missing: 571\n",
      "max missing cas: 24\n",
      "min proportion of ca-provided residues: 0.9824561403508771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "problematic_resnames = set([])\n",
    "num_problematic = 0\n",
    "missing_cas_list = []\n",
    "min_ca_proportion = 1.0 \n",
    "max_missing_cas = 0\n",
    "for data_dir in loop_over_data_dirs():\n",
    "    clean_pdb_file = data_dir / f'{data_dir.name}_clean.pdb'\n",
    "    num_residues = 0\n",
    "    with open(clean_pdb_file, 'r') as f:\n",
    "        chain = []\n",
    "        chainID = None\n",
    "        resSeq = None \n",
    "        iCode = None\n",
    "        resname = None\n",
    "        \n",
    "        CA_encountered = True\n",
    "        missing_cas = 0\n",
    "        for line in f:\n",
    "            prev_chainID = chainID \n",
    "            prev_resSeq = resSeq \n",
    "            prev_iCode = iCode\n",
    "            prev_resname = resname\n",
    "            \n",
    "            chainID = line[21]\n",
    "            resSeq = int(line[22:26])\n",
    "            iCode = line[26]\n",
    "            resname = line[17:20]\n",
    "            atomname = line[12:16].strip()\n",
    "            \n",
    "            if (chainID, resSeq, iCode) != (prev_chainID, prev_resSeq, prev_iCode):\n",
    "                num_residues += 1\n",
    "                if not CA_encountered:\n",
    "                    if not prev_resname in problematic_resnames:\n",
    "                        missing_cas += 1\n",
    "                        #print(prev_resname, clean_pdb_file.absolute(), prev_resSeq)\n",
    "                        #problematic_resnames.add(prev_resname)\n",
    "                    #raise Exception('No CA:', str(data_dir), prev_resSeq)\n",
    "                CA_encountered = False\n",
    "            if atomname == 'CA':\n",
    "                if CA_encountered:\n",
    "                    raise Exception('More than one CA:', str(data_dir), prev_resSeq)\n",
    "                CA_encountered = True\n",
    "        num_residues += 1 \n",
    "        if not CA_encountered:\n",
    "            missing_cas += 1\n",
    "            #raise Exception('No CA:', str(data_dir), prev_resSeq)\n",
    "        if missing_cas > 0:\n",
    "            num_problematic += 1\n",
    "            missing_cas_list.append(missing_cas) \n",
    "        if missing_cas > max_missing_cas:\n",
    "            max_missing_cas = missing_cas \n",
    "        if 1 - missing_cas / num_residues < min_ca_proportion:\n",
    "            min_ca_proportion = 1 - missing_cas / num_residues\n",
    "print('# of cases at least one CA is missing:', num_problematic) #571\n",
    "print('max missing cas:', max_missing_cas) #24\n",
    "print('avg missing cas:', sum(missing_cas_list) / len(missing_cas_list)) #1.54\n",
    "print('min proportion of ca-provided residues:', min_ca_proportion) #0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db2bdf-7e94-4905-bf5e-0d72bd81173f",
   "metadata": {},
   "source": [
    "### SEQRES-ATOM/HETATM comparision procedure\n",
    "* Parse seqres(list of resnames) from *_protein.pdb \n",
    "* Parse chains(list of resnames) from *_clean.pdb, based on \n",
    "  * only chainID for chain separation \n",
    "  * resSeq and iCode for residue \n",
    "* assert\n",
    "    -The keys are identical \n",
    "    -lists from ATOM/HETATM are not longer than lists from SEQRES\n",
    "    -If they have equal lengths, they are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dc043de-0eac-4a4f-961f-9f8a133a5405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_seqres(file, fasta=True):\n",
    "    seqs = {}\n",
    "    with open(file, 'r') as reader:\n",
    "        for line in reader:\n",
    "            if not line.startswith('SEQRES'):\n",
    "                continue\n",
    "            chainID = line[11]\n",
    "            if not chainID in seqs:\n",
    "                seqs[chainID] = []\n",
    "            subseq = [s.strip() for s in line[19:].split()]\n",
    "            seqs[chainID] += subseq\n",
    "        for chainID in seqs:\n",
    "            if fasta:\n",
    "                seqs[chainID] = ''.join([convert_residue.get(res, 'X') for res in seqs[chainID]])\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3ed59dc-ec31-46ac-84ec-433581a8772c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/general-set-except-refined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9228/9228 [01:02<00:00, 148.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/refined-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4059/4059 [00:26<00:00, 153.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of cases (ATOM/HETATM) <= SEQRES 69\n",
      "# of cases (ATOM/HETATM) == SEQRES 22958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_shorter = 0\n",
    "num_equal = 0\n",
    "for data_dir in loop_over_data_dirs():\n",
    "    protein_file = data_dir / f'{data_dir.name}_protein.pdb'\n",
    "    clean_file = data_dir / f'{data_dir.name}_clean.pdb'\n",
    "    \n",
    "    seqres_dict = parse_seqres(protein_file, fasta=False)\n",
    "    \n",
    "    chain_dict = {}\n",
    "    with open(clean_file, 'r') as f:\n",
    "        chain = []\n",
    "        chainID = None\n",
    "        resSeq = None \n",
    "        iCode = None\n",
    "        \n",
    "        for line in f:\n",
    "            prev_chainID = chainID \n",
    "            prev_resSeq = resSeq \n",
    "            prev_iCode = iCode \n",
    "            \n",
    "            chainID = line[21]\n",
    "            resSeq = int(line[22:26])\n",
    "            iCode = line[26]\n",
    "            resname = line[17:20]\n",
    "            \n",
    "            if chainID != prev_chainID and prev_chainID is not None:\n",
    "                chain_dict[prev_chainID] = chain \n",
    "                chain = [] \n",
    "            if chainID != prev_chainID or (resSeq, iCode) != (prev_resSeq, prev_iCode):\n",
    "                chain.append(resname) \n",
    "        chain_dict[chainID] = chain \n",
    "    \n",
    "    if not set(seqres_dict.keys()) == set(chain_dict.keys()):\n",
    "        raise Exception('SEQRES and ATOM/HETATM mismatch in chainIDS:', data_dir, set(seqres_dict.keys()), '!=', set(chain_dict.keys()))\n",
    "    \n",
    "    for chainID in seqres_dict.keys():\n",
    "        seqres_chain = seqres_dict[chainID] \n",
    "        chain = chain_dict[chainID]\n",
    "        \n",
    "        if not len(seqres_chain) >= len(chain):\n",
    "            Exception('SEQRES shorter than ATOM/HETATM:', data_dir)\n",
    "        \n",
    "        if len(seqres_chain) == len(chain):\n",
    "            num_equal += 1\n",
    "            if seqres_chain != chain:\n",
    "                Exception('SEQRES not identical to ATOM/HETATM:', data_dir)\n",
    "        else:\n",
    "            num_shorter += 1\n",
    "print('# of cases (ATOM/HETATM) <= SEQRES', num_shorter)\n",
    "print('# of cases (ATOM/HETATM) == SEQRES', num_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1768e-d613-4afc-b395-743d44f93c57",
   "metadata": {},
   "source": [
    "## Generating entrycode-FASTA index file\n",
    "\n",
    "### file format \n",
    "Each line is f'{pdb_code}\\t{FASTA}\\n'\n",
    "### procedure\n",
    "* For each data_dir:\n",
    "  * iterate lines of *_clean.pdb and collect resnames (concatenate all chains), based on change of (chainID, resSeq, iCode)\n",
    "  * Turn it into FASTA using \"convert_residue\" \n",
    "  * put it into a pdb_code-FASTA dictinoary\n",
    "* write the pdb_code-FASTA dictionary to <cc_fasta_dict.json>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9570e72-5302-42b3-a8fd-86d186bbe99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/general-set-except-refined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9228/9228 [00:27<00:00, 335.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pdbbind/v2016/refined-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4059/4059 [00:11<00:00, 359.18it/s]\n"
     ]
    }
   ],
   "source": [
    "cc_fasta_dict = {}\n",
    "for data_dir in loop_over_data_dirs():\n",
    "    clean_pdb = data_dir / f'{data_dir.name}_clean.pdb'\n",
    "    with open(clean_pdb, 'r') as f:\n",
    "        cc_chain = []\n",
    "        chainID = None\n",
    "        resSeq = None \n",
    "        iCode = None\n",
    "        \n",
    "        for line in f:\n",
    "            prev_chainID = chainID \n",
    "            prev_resSeq = resSeq \n",
    "            prev_iCode = iCode \n",
    "            \n",
    "            chainID = line[21]\n",
    "            resSeq = int(line[22:26])\n",
    "            iCode = line[26]\n",
    "            resname = line[17:20]\n",
    "            \n",
    "            if chainID != prev_chainID or (resSeq, iCode) != (prev_resSeq, prev_iCode):\n",
    "                cc_chain.append(resname) \n",
    "        \n",
    "        cc_fasta = ''.join([convert_residue.get(res, 'X') for res in cc_chain])\n",
    "        cc_fasta_dict[data_dir.name] = cc_fasta\n",
    "        \n",
    "with open('./cc_fasta_dict.json', 'w') as f:\n",
    "    json.dump(cc_fasta_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9016933-3a9b-4411-84d1-3e0444fe1171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dti",
   "language": "python",
   "name": "dti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
